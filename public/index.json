[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a group leader and the head of Bioinformatics and Omics Data Science Platform at the Berlin Institute of Medical Systems Biology, Max Delbrück Center in Berlin. I have been developing computational methods for analyzing and integrating large-scale genomics data sets since 2005. I mainly use machine learning and statistics to uncover patterns related to important biological variables such as disease state and type. I spent some time in USA, Norway, Turkey, Japan, and Switzerland in order to pursue further self-development in genomics, bioinformatics and statistics.\nThe underlying aim of my current work is utilizing complex molecular signatures to provide decision support systems for disease diagnostics and biomarker discovery. In addition to research efforts, since 2015, I have been organizing and teaching at computational genomics courses in Berlin with participants from across the world.\nto do: - add recent talks, GSCN, Summer Meeting, MPG - add courses ad - add book to featured projects - add medium blog posts\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a group leader and the head of Bioinformatics and Omics Data Science Platform at the Berlin Institute of Medical Systems Biology, Max Delbrück Center in Berlin. I have been developing computational methods for analyzing and integrating large-scale genomics data sets since 2005. I mainly use machine learning and statistics to uncover patterns related to important biological variables such as disease state and type. I spent some time in USA, Norway, Turkey, Japan, and Switzerland in order to pursue further self-development in genomics, bioinformatics and statistics.","tags":null,"title":"Altuna Akalin","type":"authors"},{"authors":[],"categories":null,"content":"","date":1569250800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569250800,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Systems biology and medicine in the genomics era","type":"talk"},{"authors":null,"categories":null,"content":"originally posted at medium.com\nWhat do pipelines do? Why do we need them? Pipelines are computational tools of convenience. Data analysis usually requires data acquisition, quality check, clean up, exploratory analysis and hypothesis driven analysis. Pipelines can automate these steps. They process raw data to a suitable format and analyze it with statistical tools or machine learning models in a streamlined way. In practical terms, a data analysis pipeline executes a chain of command-line tools and custom scripts. This usually provides processed data sets and a human readable report covering topics such as data quality, exploratory analysis etc.\nIn our field, raw data comes as text files containing sequencing reads. The reads have a 4-letter code (ACGT) and they originate from specific locations of the genome. We need to quality check the reads, align them to the genome, quantify them and run statistical/machine-learning models on them. Different command-line tools and custom scripts have to be run in sequence to achieve these tasks. If there is a problem in quality check or alignments, parts or all the steps need to be re-run with different parameters depending on the nature of the problem observed with the data. We may have to run this for hundreds of times, so automating at least part of these tasks via pipelines is beneficial.\nWhat is reproducibility? Why is it important ? Pipelines can be a great help when you have to process a dataset repeatedly with some changes in parameters or when you process multiple datasets. Since basic data processing and analysis tasks can take a lot of hands-on time, automating certain parts of these saves time. Researchers can then spend more time on visualization, communication of results or tailor made statistical/machine-learning analysis. Because of this convenience many researchers are creating pipelines and sharing them with the community via publications. Normally, when you share the pipeline you would like to make sure that your pipeline will produce the same output for other users when provided with the same input data. How can one install the exact same pipeline with the exact dependencies its creator using and make sure it produces the same output? Although it sounds like a trivial question, reports regarding “reproducibility crisis in science” shows that it is not very easy to achieve this. Other researchers repeatedly fail to reproduce published experiments. This “reproducibility crisis” is not limited to fields such as biology or psychology. Computational fields also suffer from this.\nThere are a couple of criteria for reproducible data analysis.\nData and metadata availability: Data and metadata should be available without question. Without these, there is a no way you can reproduce an analysis. In our research domain, data and metadata usually deposited to public databases after publication.\nTransparency: There should be complete transparency of the code you are using and the dependencies you need to run the code. This also extends to source code availability of your dependencies. It is undesirable to have a tool whose behaviour crucially depends on a proprietary binary blob / black box. In addition, you need to know exact versions and configurations of the dependencies to have a shot at reproducing the data analysis pipeline. Preferably, the installation procedure keeps track of the different dependency structures and installs everything you need, see the point below.\nEase of installation (installability): Computational analysis tools and pipelines should make the effort to be easily installable. I think many of us will be deterred if the pipeline has many dependencies that have to be installed separately. This will remain so even if we are promised to get a working pipeline that reproduces the authors version after we go through installation of each dependency diligently. The more dependencies a pipeline has, the more it is likely that at least one of them will be a problem during installation. Many published scientific software can not be installed. Studies claim at least 50% of the published software is uninstallable [see here \u0026amp; here]. I suspect that for the pipelines, many with more complicated dependencies, the situation is worse. People who have gone through poorly written readme files and tried to install all the dependencies know very well why “ease of installation” is important.\nRuntime environment reproducibility: The installed software should behave the same in every machine, in the sense that we need to install the very same software in every machine. Achieving this is not straightforward because the software depends on many different things from compilers, to system libraries to 3rd-party software and libraries needed. You need to control this complex system of dependencies if you want to build software exactly the same way on different machines and get the same software. The version of dependencies and how they are built will have an effect on the software you are trying to install. For example if the software you are trying to install requires Boost C++ library, having Boost version 1.68 might produce differences compared to having version 1.38. There might be bug fixes or improvements that could change the behaviour of the software we are trying to install. Therefore, this software can behave differently even though same version is installed on two different machines because of dependency differences.\nIf you can install the same exact software, built the same way with exactly the same dependencies down to the compiler, you have good chances at reproducing the runtime environment across different machines and therefore the analysis with the same input data. Only exception here is that if the software has some stochastic component that you can not control then it will not be possible to reproduce the analysis. For example, k-means clustering algorithm might produce different clustering results every time depending a random initialization procedure. If we are not able to control that behavior by setting random seed we won’t be able to reproduce the results.\nEssential ingredients of data analysis reproducibility. Reproducibility requires availability of data and being able to use the same exact software.\n","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"032bbe95b851beaa6ecec96c84cc34e1","permalink":"/post/scientific-analysis-pipelines/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/scientific-analysis-pipelines/","section":"post","summary":"originally posted at medium.com\nWhat do pipelines do? Why do we need them? Pipelines are computational tools of convenience. Data analysis usually requires data acquisition, quality check, clean up, exploratory analysis and hypothesis driven analysis. Pipelines can automate these steps. They process raw data to a suitable format and analyze it with statistical tools or machine learning models in a streamlined way. In practical terms, a data analysis pipeline executes a chain of command-line tools and custom scripts.","tags":null,"title":"Scientific Data Analysis Pipelines and Reproducibility","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":" I have been organizing and teaching hands-on courses on data analysis since 2014.\nCustom Training and Workshops We offer custom computational genomics training at your location. Our in-person workshops offer an intense experience to get you up and running with the techniques related to computational genomics. If you have a specific need in mind, get in touch via [info@rolv.io] and we can work out a curriculum.\nConsulting We offer project based consultation. If you have a project in mind, we can discuss how we can help you. Get in touch via [info@rolv.io]\nScientific/technical feasibility We can help you assess the scientific or technical feasibility of your projects. We review exsisting methodology in relation to your problem, and help you decide if your idea is feasible to accomplish with the current technology and/or current scientific knowledge.\nData analysis strategies We can help you create data analysis strategies for your computational genomics or machine learning based projects. These strategies will be based on current scientific literature and personal experiences.\n","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2429567449d9ffe2319c9e9199c67a32","permalink":"/training/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/training/","section":"","summary":"info on training activities","tags":null,"title":"Training \u0026 Consulting","type":"page"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"499ce0083c254736c3ce6499263cc146","permalink":"/project/biorxiv/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/biorxiv/","section":"project","summary":"Preprints at bioRxiv","tags":["Pubs"],"title":"","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c6c5db62244468263d6240cdd4323ec5","permalink":"/project/gscholar/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/gscholar/","section":"project","summary":"Citation statistics (H-index, i10-index) at Google Scholar","tags":["Pubs"],"title":"","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"5dc45ad418ab270053a387434b737119","permalink":"/project/pubmed/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/pubmed/","section":"project","summary":"PubMed indexed \u0026 peer-reviewed publications","tags":["Pubs"],"title":"","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d0e22af7a4265a0942ff7b2542b68db2","permalink":"/project/amlepi/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/amlepi/","section":"project","summary":"Showed specific AML patients have genome-wide defects in their DNA methylation profiles, this could be exploited for theraphy/diagnosis.","tags":["Featured","Cancer Genomics","MLstats"],"title":"AML epigenomics","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"a9300b3c66c8ff0d25cd90c34c3bca85","permalink":"/project/grb/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/grb/","section":"project","summary":"We have identified promoter features of genes under long range gene regulation using statistics and bioinformatics methods.","tags":["Featured","Gene Regulation","MLstats"],"title":"Genomic Regulatory Blocks","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"4693ee78be5e06701f2f261935141ac6","permalink":"/project/hotnot/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/hotnot/","section":"project","summary":"We showed high-occupancy target regions associated with ChIP-seq noise using ML and stats based methods.","tags":["Featured","Gene Regulation","MLstats"],"title":"HOT regions","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"1316cd1aa122360a626203abf85f34a3","permalink":"/project/maui/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/maui/","section":"project","summary":"Deep learning method for integrating multi-omics data from cancer genomics. Applied on colorectal cancer for refining subtypes.","tags":["Featured","MLstats","Cancer Genomics","Software"],"title":"multi-omics data integration","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"f790303ae4f7938435f8b517245c53c0","permalink":"/project/pigx/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/pigx/","section":"project","summary":"Reproducible, scalable and secure pipelines for genomics | RNA-seq, scRNA-seq, ChIP-seq, BS-seq","tags":["Featured","Software"],"title":"PiGx workflows","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"5370f23fb375eac8d0e19ef04fca6cea","permalink":"/project/genomation/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/genomation/","section":"project","summary":"Integrate genomic data sets via meta-region plots and heatmaps. Works with BAM, BigWig, Bed files","tags":["Featured","Software","MLstats"],"title":"R/Bioc package","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"748c8716351932dae298a27c7af3f031","permalink":"/project/methylkit/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/methylkit/","section":"project","summary":"Analyze methylation data from high-throughput BS-seq experiments","tags":["Featured","Software","MLstats"],"title":"R/Bioc package","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c1fde7b7994be54f35341da9d2fd985a","permalink":"/project/amlhydroxy/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/amlhydroxy/","section":"project","summary":"We showed WT1 mutation causes similar epigenome defects to IDH1/2 and TET2 mutations in leukemia","tags":["Featured","Cancer Genomics","MLstats"],"title":"WT1 mutation leukemia","type":"project"}]